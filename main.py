from astrbot.api.event import filter, AstrMessageEvent, MessageEventResult
from astrbot.api.star import Context, Star, register
from astrbot.api import logger
from astrbot.api.message_components import Node, Plain, Image
import aiohttp
import asyncio
import re
import os
import ssl
import yt_dlp
import certifi
import pdfplumber
import tomli
import time
from typing import Dict, Optional, TYPE_CHECKING
import json
import html
import xml.etree.ElementTree as ET

@register("summary", "whyis", "ä¸€ä¸ªç®€å•çš„è¯»å–ç½‘é¡µå†…å®¹æ€»ç»“", "1.0.0")
class MyPlugin(Star):
    URL_PATTERN = r'https?://(?:[-\w.]|(?:%[\da-fA-F]{2}))+[-\w./?=&]*'

    def __init__(self, context: Context):
        super().__init__(context)
        self.name = "Summary"
        config_path = os.path.join(os.path.dirname(__file__), "config.toml")
        with open(config_path, "rb") as f:
            config = tomli.load(f)

        self.config = config.get("Summary", {})
        dify_config = self.config.get("Dify", {})
        self.dify_enable = dify_config.get("enable", False)
        self.dify_api_key = dify_config.get("api-key", "")
        self.dify_base_url = dify_config.get("base-url", "")
        self.http_proxy = dify_config.get("http-proxy", "")

        settings = self.config.get("Settings", {})
        self.max_text_length = settings.get("max_text_length", 10000)
        self.black_list = settings.get("black_list", [])
        self.white_list = settings.get("white_list", [])

        # å­˜å‚¨æœ€è¿‘çš„é“¾æ¥å’Œå¡ç‰‡ä¿¡æ¯
        self.recent_urls = {}  # æ ¼å¼: {chat_id: {"url": url, "timestamp": timestamp}}
        self.recent_cards = {}  # æ ¼å¼: {chat_id: {"info": card_info, "timestamp": timestamp}}
        # é“¾æ¥å’Œå¡ç‰‡çš„è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
        self.expiration_time = 300  # 5åˆ†é’Ÿ

        self.http_session = aiohttp.ClientSession()

        if not self.dify_enable or not self.dify_api_key or not self.dify_base_url:
            logger.warning("Difyé…ç½®ä¸å®Œæ•´ï¼Œè‡ªåŠ¨æ€»ç»“åŠŸèƒ½å°†è¢«ç¦ç”¨")
            self.dify_enable = False

    async def close(self):
        if self.http_session:
            await self.http_session.close()
            logger.info("HTTPä¼šè¯å·²å…³é—­")

    def _check_url(self, url: str) -> bool:
        stripped_url = url.strip()
        if not stripped_url.startswith(('http://', 'https://')):
            return False
        if self.white_list and not any(stripped_url.startswith(white_url) for white_url in self.white_list):
            return False
        if any(stripped_url.startswith(black_url) for black_url in self.black_list):
            return False
        return True

    def _clean_expired_items(self):
        current_time = time.time()
        # æ¸…ç†è¿‡æœŸçš„URL
        for chat_id in list(self.recent_urls.keys()):
            if current_time - self.recent_urls[chat_id]["timestamp"] > self.expiration_time:
                del self.recent_urls[chat_id]
        # æ¸…ç†è¿‡æœŸçš„å¡ç‰‡
        for chat_id in list(self.recent_cards.keys()):
            if current_time - self.recent_cards[chat_id]["timestamp"] > self.expiration_time:
                del self.recent_cards[chat_id]

    async def get_arxiv_paper_text(self, arxiv_url, http_session=None):
        # æ­¥éª¤ 1ï¼šä» URL ä¸­æå–è®ºæ–‡ ID
        paper_id = arxiv_url.split('/')[-1]
        pdf_url = f"https://arxiv.org/pdf/{paper_id}.pdf"
        logger.info(f"ä¸‹è½½pdfæ–‡ä»¶: {pdf_url}")
        if http_session is None:
            http_session = aiohttp.ClientSession()
        try:
            timeout = aiohttp.ClientTimeout(total=60)
            ssl_context = ssl.create_default_context(cafile=certifi.where())
            async with http_session.get(pdf_url, timeout=timeout, ssl=ssl_context) as response:
                if response.status == 200:
                    # è·å–äºŒè¿›åˆ¶å†…å®¹
                    pdf_content = await response.read()
                    logger.info(f"æˆåŠŸä¸‹è½½åˆ°pdf: {pdf_url}, size: {len(pdf_content)} bytes")
                else:
                    logger.error(f"æ— æ³•ä¸‹è½½pdf, status code: {response.status}")
                    return None
            await http_session.close()
        except Exception as e:
            logger.error(f"ä¸‹è½½pdfæ—¶é”™è¯¯: {e}")
            return None
        finally:
            if http_session is None:
                await http_session.close()

        temp_pdf_path = f"{paper_id}.pdf"
        try:
            with open(temp_pdf_path, 'wb') as f:
                f.write(pdf_content)
        except Exception as e:
            logger.error(f"Error saving PDF to file: {e}")
            return None
        text_content = ""
        try:
            with pdfplumber.open(temp_pdf_path) as pdf:
                for page in pdf.pages:
                    text_content += page.extract_text() + "\n\n"
            logger.info(f"pdfæ–‡ç« å¤„ç†å®Œæ¯•")
        except Exception as e:
            logger.error(f"pdfæ–‡ç« å¤„ç†å¤±è´¥ï¼š{e}")
            text_content = "Could not extract text from PDF."

        if os.path.exists(temp_pdf_path):
            try:
                os.remove(temp_pdf_path)
            except Exception as e:
                logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶é”™è¯¯: {e}")
        return text_content

    async def get_videos(self, video_url: str) -> Optional[str]:
        # é…ç½®yt-dlpé€‰é¡¹
        output_template = os.path.join('%(id)s.%(ext)s')
        ydl_opts = {
            'outtmpl': output_template,# è¾“å‡ºæ–‡ä»¶è·¯å¾„
            'format': 'bestvideo[height<=720]',
            'merge_output_format': 'mp4',  #åˆå¹¶ä¸ºmp4æ ¼å¼
            'quiet': True,  #å‡å°‘æ§åˆ¶å°è¾“å‡º
            'no_warnings': True,  # å¿½ç•¥è­¦å‘Š
            'ignoreerrors': False,
        }

        # ä¿å­˜è§†é¢‘è·¯å¾„
        saved_path = None
        output_dir= None
        try:
            # ä½¿ç”¨yt-dlpä¸‹è½½è§†é¢‘
            logger.info(f"å¼€å§‹ä¸‹è½½è§†é¢‘: {video_url}")
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                info_dict = ydl.extract_info(video_url, download=True)
                video_id = info_dict.get('id', 'unknown')
                video_ext = info_dict.get('ext', 'mp4')
                saved_path = os.path.join(output_dir, f"{video_id}.{video_ext}")
        except Exception as e:
            logger.error(f"ä¸‹è½½è§†é¢‘æ—¶å‡ºé”™: {e}")
            saved_path = None
        return saved_path

    async def get_github_code_text(self, github_url, http_session=None):
        pass
    async def _fetch_url_content(self, url: str) -> Optional[str]:
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
            }
            # ä¸åœ¨é¡¶å±‚è®¾ç½®è¶…æ—¶å‚æ•°
            # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰é‡å®šå‘ï¼Œè·å–æœ€ç»ˆURL
            final_url = url
            try:
                # åªå‘é€HEADè¯·æ±‚æ¥æ£€æŸ¥é‡å®šå‘ï¼Œä¸è·å–å®é™…å†…å®¹
                async def check_redirect():
                    # åœ¨ä»»åŠ¡ä¸­è®¾ç½®è¶…æ—¶
                    timeout = aiohttp.ClientTimeout(total=30)
                    async with self.http_session.head(url, headers=headers, allow_redirects=True,
                                                      timeout=timeout) as head_response:
                        if head_response.status == 200:
                            return str(head_response.url)
                        return url

                final_url = await asyncio.create_task(check_redirect())
                if final_url != url:
                    logger.info(f"æ£€æµ‹åˆ°é‡å®šå‘: {url} -> {final_url}")
            except Exception as e:
                logger.warning(f"æ£€æŸ¥é‡å®šå‘å¤±è´¥: {e}, ä½¿ç”¨åŸå§‹URL")
                final_url = url

            # ä½¿ç”¨ Jina AI è·å–å†…å®¹ï¼ˆä½¿ç”¨æœ€ç»ˆURLï¼‰
            logger.info(f"ä½¿ç”¨ Jina AI è·å–å†…å®¹: {final_url}")
            try:
                jina_url = f"https://r.jina.ai/{final_url}"

                async def get_jina_content():
                    # åœ¨ä»»åŠ¡ä¸­è®¾ç½®è¶…æ—¶
                    timeout = aiohttp.ClientTimeout(total=30)
                    async with self.http_session.get(jina_url, headers=headers, timeout=timeout) as jina_response:
                        if jina_response.status == 200:
                            content = await jina_response.text()
                            return content
                        return None

                content = await asyncio.create_task(get_jina_content())
                if content:
                    logger.info(f"ä» Jina AI è·å–å†…å®¹æˆåŠŸ: {jina_url}, å†…å®¹é•¿åº¦: {len(content)}")
                    return content
                else:
                    logger.error(f"ä» Jina AI è·å–å†…å®¹å¤±è´¥ï¼ŒURL: {jina_url}")
            except Exception as e:
                logger.error(f"ä½¿ç”¨Jina AIè·å–å†…å®¹å¤±è´¥: {e}")

            # å¦‚æœ Jina AI å¤±è´¥ï¼Œå°è¯•ç›´æ¥è·å–
            logger.info(f"Jina AI å¤±è´¥ï¼Œå°è¯•ç›´æ¥è·å–: {final_url}")
            try:
                async def get_direct_content():
                    # åœ¨ä»»åŠ¡ä¸­è®¾ç½®è¶…æ—¶
                    timeout = aiohttp.ClientTimeout(total=30)
                    async with self.http_session.get(final_url, headers=headers, timeout=timeout) as response:
                        if response.status != 200:
                            logger.error(f"ç›´æ¥è·å–URLå¤±è´¥: {response.status}, URL: {final_url}")
                            return None

                        return await response.text()

                content = await asyncio.create_task(get_direct_content())
                if content and len(content) > 500:  # ç¡®ä¿å†…å®¹æœ‰è¶³å¤Ÿé•¿åº¦
                    logger.info(f"ç›´æ¥ä»URLè·å–å†…å®¹æˆåŠŸ: {final_url}, å†…å®¹é•¿åº¦: {len(content)}")
                    return content
            except Exception as e:
                logger.warning(f"ç›´æ¥è·å–å†…å®¹å¤±è´¥: {e}")

            # å°è¯•ä½¿ç”¨å¤‡ç”¨æ–¹æ³•ç›´æ¥è·å–
            return await self._fetch_url_content_direct(final_url)
        except asyncio.TimeoutError:
            logger.error(f"è·å–URLå†…å®¹è¶…æ—¶: URL: {url}")
            return None
        except Exception as e:
            logger.error(f"è·å–URLå†…å®¹æ—¶å‡ºé”™: {e}, URL: {url}")
            return None

    async def _fetch_url_content_direct(self, url: str) -> Optional[str]:
        """ç›´æ¥è·å–URLå†…å®¹çš„å¤‡ç”¨æ–¹æ³•"""
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36",
                "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Cache-Control": "no-cache",
                "Pragma": "no-cache"
            }
            # ä¸åœ¨é¡¶å±‚è®¾ç½®è¶…æ—¶å‚æ•°

            logger.info(f"å¤‡ç”¨æ–¹æ³•å°è¯•è·å–: {url}")

            async def get_backup_content():
                # åœ¨ä»»åŠ¡ä¸­è®¾ç½®è¶…æ—¶
                timeout = aiohttp.ClientTimeout(total=30)
                async with self.http_session.get(url, headers=headers, timeout=timeout,
                                                 allow_redirects=True) as response:
                    if response.status != 200:
                        logger.warning(f"å¤‡ç”¨æ–¹æ³•è·å–å¤±è´¥: {response.status}, URL: {url}")
                        return None

                    content_type = response.headers.get('Content-Type', '')
                    logger.info(f"å†…å®¹ç±»å‹: {content_type}")

                    # å°è¯•è·å–æ–‡æœ¬å†…å®¹ï¼Œå³ä½¿ä¸æ˜¯æ ‡å‡†çš„HTMLæˆ–JSON
                    try:
                        content = await response.text()
                        if content and len(content) > 500:  # ç¡®ä¿å†…å®¹æœ‰è¶³å¤Ÿé•¿åº¦
                            return content
                        return None
                    except Exception as text_error:
                        logger.warning(f"è·å–æ–‡æœ¬å†…å®¹å¤±è´¥: {text_error}")
                        return None

            content = await asyncio.create_task(get_backup_content())

            if content:
                logger.info(f"å¤‡ç”¨æ–¹æ³•è·å–å†…å®¹æˆåŠŸ: {url}, å†…å®¹é•¿åº¦: {len(content)}")
                return content
            return None
        except Exception as e:
            logger.error(f"å¤‡ç”¨æ–¹æ³•è·å–URLå†…å®¹å¤±è´¥: {e}")
            return None
    async def _upload_file_to_dify(self, file_path: str) -> Optional[str]:
        try:
            url = f"{self.dify_base_url}/files/upload"
            headers = {
                "Authorization": f"Bearer {self.dify_api_key}"
            }
            data = aiohttp.FormData()
            with open(file_path, "rb") as f:
                file_content = f.read()  # è¯»å–æ–‡ä»¶å†…å®¹åˆ°å†…å­˜
            data.add_field("file", file_content, filename="video.mp4", content_type="video/mp4")
            data.add_field("user", "summary")
            async with self.http_session.post(
                url=url,
                headers=headers,
                data=data,
                proxy=self.http_proxy if self.http_proxy else None
            ) as response:
                if response.status == 200 or 201:
                    result = await response.json()
                    file_id = result.get("id")  # å‡è®¾è¿”å›çš„å“åº”ä¸­åŒ…å«æ–‡ä»¶ ID
                    logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œæ–‡ä»¶ID: {file_id}")
                    if os.path.exists(file_path):
                        try:
                            os.remove(file_path)
                        except Exception as e:
                            logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶é”™è¯¯: {e}")
                    return file_id
                else:
                    if os.path.exists(file_path):
                        try:
                            os.remove(file_path)
                        except Exception as e:
                            logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶é”™è¯¯: {e}")
                    error_text = await response.text()
                    logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {response.status} - {error_text}")
                    return None
        except Exception as e:
            logger.error(f"æ–‡ä»¶ä¸Šä¼ æ—¶å‡ºé”™: {e}")
            return None
    async def _send_to_dify(self, content: str, is_xiaohongshu: bool = False,is_video = False) -> Optional[str]:
        if not self.dify_enable:
            return None
        headers = {
            "Authorization": f"Bearer {self.dify_api_key}",
            "Content-Type": "application/json"
        }
        url = f"{self.dify_base_url}/chat-messages"
        try:
            # æ£€æŸ¥æ˜¯å¦ä¸ºGitHubä¸ªäººä¸»é¡µ
            is_github_profile = "github.com" in content and (
                        "overview" in content.lower() or "repositories" in content.lower())
            if is_video:
                video_id = await self._upload_file_to_dify(content)
                prompt = f"""è¯·å¯¹ä»¥ä¸‹è§†é¢‘è¿›è¡Œè¯¦ç»†å…¨é¢çš„æè¿°æˆ–è€…æ€»ç»“ï¼Œæä¾›ä¸°å¯Œçš„ä¿¡æ¯ï¼š
                1. ğŸ“ è§†é¢‘æè¿°çš„å†…å®¹ï¼Œå‡ºç°æˆ–è€…å‘ç”Ÿçš„äº‹
                2. ğŸ”‘ è¯¦ç»†çš„æ ¸å¿ƒè¦ç‚¹ï¼ˆ5-7ç‚¹ï¼Œæ¯ç‚¹åŒ…å«è¶³å¤Ÿç»†èŠ‚ï¼‰
                3. ğŸ’¡ å¦‚æœæœ‰è®ºè¿°åˆ™é˜è¿°ä½œè€…çš„ä¸»è¦è§‚ç‚¹ã€æ–¹æ³•æˆ–å»ºè®®ï¼ˆå¯é€‰ï¼‰
                4. ğŸ’° å®ç”¨ä»·å€¼å’Œå¯è¡Œçš„è¡ŒåŠ¨å»ºè®®ï¼ˆå¯é€‰ï¼‰
                5. ğŸ·ï¸ ç›¸å…³æ ‡ç­¾ï¼ˆ3-5ä¸ªï¼‰
                """
                payload = {
                         "inputs": {},
                    "files": [
                        {
                            "type": "video",
                            "transfer_method": "local_file",
                            "upload_file_id": video_id
                        }
                    ],
                    "query": prompt,
                    "response_mode": "blocking",
                    "conversation_id": None,
                    "user": "summary"
                }
            elif is_xiaohongshu:
                prompt = f"""è¯·å¯¹ä»¥ä¸‹å°çº¢ä¹¦ç¬”è®°è¿›è¡Œè¯¦ç»†å…¨é¢çš„æ€»ç»“ï¼Œæä¾›ä¸°å¯Œçš„ä¿¡æ¯ï¼š
    1. ğŸ“ å…¨é¢æ¦‚æ‹¬ç¬”è®°çš„æ ¸å¿ƒå†…å®¹å’Œä¸»æ—¨ï¼ˆ2-3å¥è¯ï¼‰
    2. ğŸ”‘ è¯¦ç»†çš„æ ¸å¿ƒè¦ç‚¹ï¼ˆ5-7ç‚¹ï¼Œæ¯ç‚¹åŒ…å«è¶³å¤Ÿç»†èŠ‚ï¼‰
    3. ğŸ’¡ ä½œè€…çš„ä¸»è¦è§‚ç‚¹ã€æ–¹æ³•æˆ–å»ºè®®ï¼ˆè‡³å°‘3ç‚¹ï¼‰
    4. ğŸ’° å®ç”¨ä»·å€¼å’Œå¯è¡Œçš„è¡ŒåŠ¨å»ºè®®
    5. ğŸ·ï¸ ç›¸å…³æ ‡ç­¾ï¼ˆ3-5ä¸ªï¼‰

    è¯·ç¡®ä¿æ€»ç»“å†…å®¹è¯¦å°½ï¼Œæ•æ‰åŸæ–‡ä¸­æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼Œä¸è¦é—æ¼å…³é”®ç‚¹ã€‚

    åŸæ–‡å†…å®¹ï¼š
    {content}
    """
                payload = {
                    "inputs": {},
                    "query": prompt,
                    "response_mode": "blocking",
                    "conversation_id": None,
                    "user": "summary"
                }
            elif 'arxiv' in content:
                prompt = f"""è¯·å¯¹ä»¥ä¸‹arxivè®ºæ–‡è¿›è¡Œéå¸¸è¯¦ç»†ã€å…¨é¢çš„æ€»ç»“ï¼Œç¡®ä¿æ¶µç›–æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼š
                   1. ğŸ“ è®ºæ–‡çš„ä¸»è¦è§‚ç‚¹
                   2. ğŸ”‘ è¯¦ç»†çš„å…³é”®è¦ç‚¹æ ¸å¿ƒå†…å®¹
                   3. ğŸ’¡ å®éªŒæ–¹æ³•ç»†èŠ‚æ€»ç»“ï¼Œå®éªŒæ•°æ®å¤„ç†
                   4. ğŸ“‹ å®éªŒç»“æœæ€»ç»“
                   5. ğŸ¯ ç›¸æ¯”ä¸ä¼ ç»Ÿçš„åˆ›æ–°ç‚¹
                   6. ğŸ·ï¸ ç›¸å…³é¢†åŸŸæ ‡ç­¾ï¼ˆ4-6ä¸ªï¼‰
                   åŸæ–‡å†…å®¹ï¼š
                   {content}
                   """
                payload = {
                    "inputs": {},
                    "query": prompt,
                    "response_mode": "blocking",
                    "conversation_id": None,
                    "user": "summary"
                }
            elif is_github_profile:
                prompt = f"""è¯·å¯¹ä»¥ä¸‹GitHubä¸ªäººä¸»é¡µå†…å®¹è¿›è¡Œå…¨é¢è€Œè¯¦ç»†çš„æ€»ç»“ï¼š
    1. ğŸ“ å¼€å‘è€…èº«ä»½å’Œä¸“ä¸šé¢†åŸŸçš„å®Œæ•´æ¦‚è¿°ï¼ˆ3-4å¥è¯ï¼‰
    2. ğŸ”‘ ä¸»è¦é¡¹ç›®å’Œè´¡çŒ®ï¼ˆåˆ—å‡ºæ‰€æœ‰å¯è§çš„é‡è¦é¡¹ç›®åŠå…¶åŠŸèƒ½æè¿°ï¼‰
    3. ğŸ’» æŠ€æœ¯æ ˆå’Œä¸“ä¸šæŠ€èƒ½ï¼ˆå°½å¯èƒ½è¯¦ç»†åˆ—å‡ºæ‰€æœ‰æåˆ°çš„æŠ€æœ¯ï¼‰
    4. ğŸš€ å¼€å‘é‡ç‚¹å’Œç‰¹è‰²é¡¹ç›®ï¼ˆè¯¦ç»†æè¿°2-3ä¸ªç½®é¡¶é¡¹ç›®ï¼‰
    5. ğŸ“Š GitHubæ´»è·ƒåº¦å’Œè´¡çŒ®æƒ…å†µ
    6. ğŸŒŸ ä¸ªäººæˆå°±å’Œç‰¹è‰²å†…å®¹
    7. ğŸ·ï¸ æŠ€æœ¯é¢†åŸŸæ ‡ç­¾ï¼ˆ4-6ä¸ªï¼‰

    è¯·ç¡®ä¿æ€»ç»“æå…¶å…¨é¢ï¼Œä¸è¦é—æ¼ä»»ä½•é‡è¦ç»†èŠ‚ï¼Œåº”åŒ…å«ä¸ªäººç®€ä»‹ã€é¡¹ç›®æè¿°ã€æŠ€æœ¯æ ˆç­‰æ‰€æœ‰ç›¸å…³ä¿¡æ¯ã€‚

    åŸæ–‡å†…å®¹ï¼š
    {content}
    """
                payload = {
                    "inputs": {},
                    "query": prompt,
                    "response_mode": "blocking",
                    "conversation_id": None,
                    "user": "summary"
                }
            else:
                prompt = f"""è¯·å¯¹ä»¥ä¸‹å†…å®¹è¿›è¡Œéå¸¸è¯¦ç»†ã€å…¨é¢çš„æ€»ç»“ï¼Œç¡®ä¿æ¶µç›–æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼š
    1. ğŸ“ å†…å®¹çš„å®Œæ•´ä¸»æ—¨å’Œæ ¸å¿ƒå†…å®¹ï¼ˆ3-5å¥è¯ï¼‰
    2. ğŸ”‘ è¯¦ç»†çš„å…³é”®è¦ç‚¹ï¼ˆ5-8ç‚¹ï¼Œæ¯ç‚¹åŒ…å«å……åˆ†ç»†èŠ‚ï¼Œä¸é—æ¼é‡è¦ä¿¡æ¯ï¼‰
    3. ğŸ’¡ ä¸»è¦è§‚ç‚¹ã€æ–¹æ³•æˆ–ä»·å€¼ï¼ˆ3-5ç‚¹ï¼‰
    4. ğŸ“‹ æ¨¡å‹çš„ç»“æ„ä»¥åŠä½¿ç”¨çš„æ•°æ®é›†ï¼Œæˆ–è€…å®éªŒå¾—åˆ°äº†ä»€ä¹ˆç»“æœ
    5. ğŸ¯ ç›¸æ¯”ä¸ä¼ ç»Ÿçš„åˆ›æ–°ç‚¹
    6. ğŸ·ï¸ ç›¸å…³é¢†åŸŸæ ‡ç­¾ï¼ˆ4-6ä¸ªï¼‰
    
    è¯·ç¡®ä¿æ€»ç»“æå…¶å…¨é¢ï¼Œæ¯ä¸ªè¦ç‚¹éƒ½æœ‰è¶³å¤Ÿçš„ä¸Šä¸‹æ–‡å’Œç»†èŠ‚è§£é‡Šï¼Œä¸è¦ç®€åŒ–æˆ–çœç•¥é‡è¦å†…å®¹ã€‚
    æ€»ç»“åº”è¯¥æ˜¯åŸå§‹å†…å®¹çš„å®Œæ•´ç¼©å½±ï¼Œè®©è¯»è€…æ— éœ€é˜…è¯»åŸæ–‡ä¹Ÿèƒ½è·å–æ‰€æœ‰å…³é”®ä¿¡æ¯ã€‚

    åŸæ–‡å†…å®¹ï¼š
    {content}
    """
                payload = {
                    "inputs": {},
                    "query": prompt,
                    "response_mode": "blocking",
                    "conversation_id": None,
                    "user": "summary"
                }

            async with self.http_session.post(
                    url=url,
                    headers=headers,
                    json=payload,
                    proxy=self.http_proxy if self.http_proxy else None
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    return result.get("answer", "")
                else:
                    error_text = await response.text()
                    logger.error(f"è°ƒç”¨Dify APIå¤±è´¥: {response.status} - {error_text}")
                    return None


        except Exception as e:
            logger.error(f"è°ƒç”¨Dify APIæ—¶å‡ºé”™: {e}")
            return None

    def _process_xml_message(self, event:AstrMessageEvent) -> Optional[Dict]:
        try:
            content = event.get_messages()
            msg_id = event.get_message_id()
            logger.info(f"æ’ä»¶å¤„ç†XMLæ¶ˆæ¯: MsgId={msg_id}")
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºXML
            if not content.strip().startswith('<'):
                logger.warning("æ¶ˆæ¯å†…å®¹ä¸æ˜¯XMLæ ¼å¼")
                return None
            logger.debug(f"å®Œæ•´XMLå†…å®¹: {content}")

            try:
                root = ET.fromstring(content)
                logger.info(f"è§£æXMLæ ¹èŠ‚ç‚¹: {root.tag}")

                # è®°å½•æ‰€æœ‰å­èŠ‚ç‚¹ä»¥ä¾¿è°ƒè¯•
                for child in root:
                    logger.debug(f"å­èŠ‚ç‚¹: {child.tag}")
            except ET.ParseError as e:
                logger.error(f"XMLè§£æé”™è¯¯: {str(e)}")
                logger.error(f"XMLå†…å®¹ç‰‡æ®µ: {content[:200]}...")
                return None

            appmsg = root.find('appmsg')
            if appmsg is None:
                logger.warning("æœªæ‰¾åˆ° appmsg èŠ‚ç‚¹")
                return None

            logger.info("æ‰¾åˆ° appmsg èŠ‚ç‚¹")

            # è®°å½•appmsgçš„æ‰€æœ‰å­èŠ‚ç‚¹
            for child in appmsg:
                logger.debug(f"appmsgå­èŠ‚ç‚¹: {child.tag} = {child.text if child.text else ''}")

            title_elem = appmsg.find('title')
            des_elem = appmsg.find('des')
            url_elem = appmsg.find('url')
            type_elem = appmsg.find('type')

            title = title_elem.text if title_elem is not None and title_elem.text else ""
            description = des_elem.text if des_elem is not None and des_elem.text else ""
            url = url_elem.text if url_elem is not None and url_elem.text else None
            type_value = type_elem.text if type_elem is not None and type_elem.text else ""

            logger.info(f"æå–çš„æ ‡é¢˜: {title}")
            logger.info(f"æå–çš„æè¿°: {description}")
            logger.info(f"æå–çš„URL: {url}")
            logger.info(f"æ¶ˆæ¯ç±»å‹å€¼: {type_value}")

            if url is None or not url.strip():
                logger.warning("URLä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
                return None

            url = html.unescape(url)
            logger.info(f"å¤„ç†åçš„URL: {url}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯å°çº¢ä¹¦
            is_xiaohongshu = '<appname>å°çº¢ä¹¦</appname>' in content
            if is_xiaohongshu:
                logger.info("æ£€æµ‹åˆ°å°çº¢ä¹¦å¡ç‰‡")

            result = {
                'title': title,
                'description': description,
                'url': url,
                'is_xiaohongshu': is_xiaohongshu,
                'type': type_value
            }
            logger.info(f"æå–çš„ä¿¡æ¯: {result}")
            return result

        except ET.ParseError as e:
            logger.error(f"XMLè§£æé”™è¯¯: {str(e)}")
            logger.error(f"XMLå†…å®¹ç‰‡æ®µ: {content[:200] if 'content' in locals() else ''}...")
            return None
        except Exception as e:
            logger.error(f"å¤„ç†XMLæ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}")
            logger.exception(e)
            return None

    async def _process_url(self, url: str) -> Optional[str]:
        try:
            if url.endswith(".mp4"):
                return await self._send_to_dify(url,is_video=True)
            videos = ["bilibili", "youtube"]
            url_content = ""
            for video in videos:
                if video in url:
                    url_content = await self.get_videos(url) #è¿”å›ç¼“å­˜çš„è§†é¢‘è·¯å¾„
                    return await self._send_to_dify(url_content)
            if 'arxiv' in url:
                url_content += "\narxivè®ºæ–‡å…·ä½“å†…å®¹å¦‚ä¸‹:\n"
                url_content += await self.get_arxiv_paper_text(url)
            elif 'github' in url:
                url_content += "\ngithubé¡¹ç›®ä»£ç å†…å®¹å¦‚ä¸‹:\n"
                url_content += await self.get_github_code_text(url)
            else:
                url_content += await self._fetch_url_content(url)
            if not url_content:
                return None
            url_content = html.unescape(url_content)
            return await self._send_to_dify(url_content)
        except Exception as e:
            logger.error(f"å¤„ç†URLæ—¶å‡ºé”™: {e}")
            return None

    async def _handle_card_message(self,event: AstrMessageEvent, info: Dict) -> bool:
        chat_id = event.get_sender_name()
        try:
            # è·å–URLå†…å®¹
            url = info['url']
            logger.info(f"å¼€å§‹è·å–å¡ç‰‡URLå†…å®¹: {url}")
            url_content = await self._fetch_url_content(url)

            if not url_content:
                logger.warning(f"æ— æ³•è·å–å¡ç‰‡å†…å®¹: {url}")
                return False

            logger.info(f"æˆåŠŸè·å–å¡ç‰‡å†…å®¹ï¼Œé•¿åº¦: {len(url_content)}")

            # æ„å»ºè¦æ€»ç»“çš„å†…å®¹
            content_to_summarize = f"""
      æ ‡é¢˜ï¼š{info['title']}
      æè¿°ï¼š{info['description']}
      æ­£æ–‡ï¼š{url_content}
      """
            # è°ƒç”¨Dify APIç”Ÿæˆæ€»ç»“
            is_xiaohongshu = info.get('is_xiaohongshu', False)
            logger.info(f"å¼€å§‹ç”Ÿæˆæ€»ç»“, æ˜¯å¦å°çº¢ä¹¦: {is_xiaohongshu}")
            summary = await self._send_to_dify(content_to_summarize, is_xiaohongshu=is_xiaohongshu)

            if not summary:
                logger.error("ç”Ÿæˆæ€»ç»“å¤±è´¥")
                return False

            logger.info(f"æˆåŠŸç”Ÿæˆæ€»ç»“ï¼Œé•¿åº¦: {len(summary)}")

            # æ ¹æ®å¡ç‰‡ç±»å‹è®¾ç½®å‰ç¼€
            prefix = "ğŸ¯ å°çº¢ä¹¦ç¬”è®°è¯¦ç»†æ€»ç»“å¦‚ä¸‹" if is_xiaohongshu else "ğŸ¯ å¡ç‰‡å†…å®¹è¯¦ç»†æ€»ç»“å¦‚ä¸‹"

            logger.info("æ€»ç»“å·²å‘é€")
            return False  # é˜»æ­¢åç»­å¤„ç†

        except Exception as e:
            logger.error(f"å¤„ç†å¡ç‰‡æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            logger.exception(e)  # è®°å½•å®Œæ•´å †æ ˆä¿¡æ¯
            return False

    async def handle_article_message(self, event,message: Dict) -> bool:
        """å¤„ç†æ–‡ç« ç±»å‹æ¶ˆæ¯ï¼ˆå¾®ä¿¡å…¬ä¼—å·æ–‡ç« ç­‰ï¼‰"""
        if not self.dify_enable:
            return
        content = event.get_messages()
        chat_id = event.get_message_id()
        try:
            card_info = self._process_xml_message(message)
            if not card_info:
                logger.warning("æ–‡ç« æ¶ˆæ¯è§£æå¤±è´¥")
                return

            logger.info(f"è¯†åˆ«ä¸ºæ–‡ç« æ¶ˆæ¯: {card_info['title']}")

            # å­˜å‚¨å¡ç‰‡ä¿¡æ¯ä¾›åç»­ä½¿ç”¨
            self.recent_cards[chat_id] = {
                "info": card_info,
                "timestamp": time.time()
            }
            logger.info(f"å·²å­˜å‚¨æ–‡ç« ä¿¡æ¯: {card_info['title']} ä¾›åç»­æ€»ç»“ä½¿ç”¨")
            event.plain_result("ğŸ“° æ£€æµ‹åˆ°æ–‡ç« ï¼Œå‘é€\"/æ€»ç»“\"å‘½ä»¤å¯ä»¥ç”Ÿæˆå†…å®¹æ€»ç»“")

            return
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ç« æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            logger.exception(e)
            return

    async def handle_file_message(self, event, message: Dict) -> bool:
        """å¤„ç†æ–‡ä»¶ç±»å‹æ¶ˆæ¯ï¼ˆåŒ…æ‹¬å¡ç‰‡æ¶ˆæ¯ï¼‰"""
        if not self.dify_enable:
            return

        chat_id = message.get("FromWxid", "")
        msg_type = message.get("MsgType", 0)

        # æ£€æŸ¥æ˜¯å¦æ˜¯å¡ç‰‡æ¶ˆæ¯ï¼ˆç±»å‹49ï¼‰
        if msg_type != 49:
            logger.info(f"éå¡ç‰‡æ¶ˆæ¯ï¼Œè·³è¿‡å¤„ç†: MsgType={msg_type}")
            return

        logger.info(f"æ”¶åˆ°å¡ç‰‡æ¶ˆæ¯: MsgType={msg_type}, chat_id={chat_id}")

        try:
            # å¤„ç†XMLæ¶ˆæ¯
            card_info = self._process_xml_message(message)
            if not card_info:
                logger.warning("å¡ç‰‡æ¶ˆæ¯è§£æå¤±è´¥")
                return

            logger.info(f"è¯†åˆ«ä¸ºå¡ç‰‡æ¶ˆæ¯: {card_info['title']}")

            # å­˜å‚¨å¡ç‰‡ä¿¡æ¯ä¾›åç»­ä½¿ç”¨
            self.recent_cards[chat_id] = {
                "info": card_info,
                "timestamp": time.time()
            }
            logger.info(f"å·²å­˜å‚¨å¡ç‰‡ä¿¡æ¯: {card_info['title']} ä¾›åç»­æ€»ç»“ä½¿ç”¨")
            event.plain_result(chat_id, "ğŸ“ æ£€æµ‹åˆ°å¡ç‰‡ï¼Œå‘é€\"/æ€»ç»“\"å‘½ä»¤å¯ä»¥ç”Ÿæˆå†…å®¹æ€»ç»“")
        except Exception as e:
            logger.error(f"å¤„ç†æ–‡ä»¶æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
            logger.exception(e)


    async def initialize(self):
        """å¯é€‰æ‹©å®ç°å¼‚æ­¥çš„æ’ä»¶åˆå§‹åŒ–æ–¹æ³•ï¼Œå½“å®ä¾‹åŒ–è¯¥æ’ä»¶ç±»ä¹‹åä¼šè‡ªåŠ¨è°ƒç”¨è¯¥æ–¹æ³•ã€‚"""


    @filter.command("summarize")
    async def summarize (self, event: AstrMessageEvent):
        """è¿™æ˜¯ä¸€ä¸ª summarizeæŒ‡ä»¤"""
        logger.info("ä½¿ç”¨æ€»ç»“")
        message_chain = event.get_messages()
        summarize = 1
        for msg in message_chain:
            if msg.type == 'Reply':
                yield event.plain_result("è§†é¢‘æ€»ç»“è°ƒè¯•ä¸­ï¼Œè¯·å‹¿å ç”¨å›å¤")
                # å¤„ç†å›å¤æ¶ˆæ¯
                from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
                assert isinstance(event, AiocqhttpMessageEvent)
                client = event.bot
                payload = {
                    "message_id": msg.id
                }
                response = await client.api.call_action('get_msg', **payload)  # è°ƒç”¨ åè®®ç«¯  API
                reply_msg = response['message']

                for msg in reply_msg:
                    if msg['type'] == 'video':
                        summarize = 0
                        from astrbot.core.platform.sources.aiocqhttp.aiocqhttp_message_event import AiocqhttpMessageEvent
                        assert isinstance(event, AiocqhttpMessageEvent)
                        client = event.bot
                        payloads2 = {
                            "file_id": msg['data']['file']
                        }
                        response = await client.api.call_action('get_file', **payloads2)
                        localdiskpath = response['file']
                        summary = await self._process_url(localdiskpath)
                        if summary:
                            node = Node(
                                uin="3967575984",
                                name="whyiså®åœ¨",
                                content=[
                                    Plain(f"ğŸ¯ è¯¦ç»†å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š\n\n{summary}"),
                                    Image.fromFileSystem("./data/plugins/summary-master/mizunashi.jpg")
                                ]
                            )
                            yield event.chain_result([node])
                        yield event.plain_result("æ‚¨æŒ‡å®šçš„è§†é¢‘å·²ç»æ”¶åˆ°äº†å–µ~")
        if summarize:
            content = message_chain[0]
            text = content.text[10:]
            chat_id = event.get_sender_name()

            urls = re.findall(self.URL_PATTERN, text)
            if urls:
                url = urls[0]
                yield event.plain_result(f"æ‰¾åˆ°URLï¼Œæ­£åœ¨ä¸ºæ‚¨ç”Ÿæˆè¯¦ç»†å†…å®¹æ€»ç»“")
                try:
                    summary = await self._process_url(url)
                    if summary:
                        node = Node(
                            uin="3967575984",
                            name="whyiså®åœ¨",
                            content=[
                                Plain(f"ğŸ¯ è¯¦ç»†å†…å®¹æ€»ç»“å¦‚ä¸‹ï¼š\n\n{summary}"),
                                Image.fromFileSystem("./data/plugins/summary-master/mizunashi.jpg")
                            ]
                        )
                        yield event.chain_result([node])
                        # æ€»ç»“ååˆ é™¤è¯¥URL
                        del self.recent_urls[chat_id]
                    else:
                        yield event.plain_result("âŒ æŠ±æ­‰ï¼Œç”Ÿæˆæ€»ç»“å¤±è´¥")
                except Exception as e:
                    logger.error(f"å¤„ç†URLæ—¶å‡ºé”™: {e}")
                    event.plain_result("âŒ æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
            else:
                yield event.plain_result(f"æ²¡æœ‰æ‰¾åˆ°URL")

    async def terminate(self):
        """å¯é€‰æ‹©å®ç°å¼‚æ­¥çš„æ’ä»¶é”€æ¯æ–¹æ³•ï¼Œå½“æ’ä»¶è¢«å¸è½½/åœç”¨æ—¶ä¼šè°ƒç”¨ã€‚"""
